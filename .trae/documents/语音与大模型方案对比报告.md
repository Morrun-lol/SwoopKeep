# 语音识别与大模型方案对比报告（国内网络优先）

## 1. 现状（本项目当前实现）

### 1.1 语音→文字（Speech-to-Text, STT）
- iOS/Android 真机（Capacitor 容器）：优先使用系统原生语音识别（`@capacitor-community/speech-recognition`），在设备端完成识别，得到文本后再走“语义解析”。
- 桌面端（Electron）：使用科大讯飞 IAT（WebSocket）由主进程代理实现。
- 兜底（Web/API）：`/api/ai/transcribe` 可走 OpenAI Whisper（若配置了 `OPENAI_API_KEY`）。

### 1.2 文本→结构化账单（LLM 语义解析）
- 服务端 `/api/ai/parse-expense`：优先 DeepSeek（`DEEPSEEK_API_KEY`），若未配置则退化到 OpenAI（`OPENAI_API_KEY`）。

### 1.3 图片→文字（OCR/Vision）
- 优先走 `/api/ai/recognize-image`（OpenAI Vision，需 `OPENAI_API_KEY`）。
- 若服务不可用/网络受限：前端可回落到本地 `tesseract.js`（中文识别，耗时更长）。

## 2. 国内网络优先策略（目标）

1) 真机 App 内尽量不依赖境外网络：STT 优先本机系统识别；LLM 优先 DeepSeek；OCR 优先本地/国内可访问服务。

2) 对外网依赖的能力保持“可选增强”：例如 Whisper/Vision 仅在用户明确配置且网络可达时启用。

## 3. 方案对比（STT）

| 方案 | 网络依赖 | 识别速度 | 准确率（普通话） | 成本 | 端侧隐私 | 适配复杂度 | 备注 |
|---|---|---|---|---|---|---|---|
| iOS/Android 系统原生识别（Capacitor SpeechRecognition） | 低/中（由系统决定） | 快 | 高 | 低 | 高 | 低 | 适合真机 App；无需自建服务；对“离线/弱网”更友好 |
| 科大讯飞 IAT 云端 WebSocket | 中（需访问讯飞域名） | 快 | 高 | 中 | 中 | 中 | 适合国内；可控；需要管理 `APPID/APIKey/Secret` |
| OpenAI Whisper（服务端转写） | 高（境外/不稳定） | 中 | 高 | 中/高 | 中 | 中 | 国内环境经常不可达或波动；适合作为可选兜底 |

## 4. 方案对比（LLM 语义解析）

| 方案 | 国内可用性 | 响应速度 | 成本 | 结果一致性 | 工程接入 | 备注 |
|---|---|---|---|---|---|---|
| DeepSeek（OpenAI 兼容接口） | 高 | 快 | 低/中 | 高 | 低 | 推荐默认；本项目已优先使用 |
| OpenAI（Chat/JSON 结构化） | 低/不稳定 | 中 | 中/高 | 高 | 低 | 不建议作为默认；仅可选 |
| 其它国内大模型（如通义千问/文心等） | 高 | 中 | 中 | 中/高 | 中 | 可作为后续扩展（需新增 provider 适配层） |

## 5. 科大讯飞 SDK 兼容性评估（结论导向）

### 5.1 本项目是否“必须集成原生 SDK”？
- 不必须。
- 若使用“讯飞云端 WebSocket IAT API”：客户端仅需能发起 HTTPS/WebSocket 请求；对 iOS/Android CPU 架构没有原生库依赖。
- 若使用“讯飞原生 SDK”：需要在 iOS/Android 工程中集成对应的静态/动态库，并关注最低系统版本、权限声明、架构（arm64）与审核要求。

### 5.2 本项目当前更适合哪种方式
- 真机 App：优先系统原生识别（最低侵入、稳定、隐私更好）。
- 若需要“统一识别体验/更强中文口语适配”：可选用讯飞云端 WebSocket 作为服务器端 STT（或在 Capacitor 插件层做一套可切换策略）。

## 6. 建议落地路线（按风险从低到高）

1) 默认启用：真机端系统原生识别 + DeepSeek 语义解析（国内优先）。
2) 增强项：图片识别优先本地 OCR（tesseract），有能力再启用云端 Vision（可选）。
3) 兼容增强：对“系统识别不可用/权限受限”的场景，增加讯飞云端 STT 作为备选（需新增后端 provider）。

## 7. 验收/指标建议（便于 QA）

### 7.1 STT（语音→文字）
- 首包响应：开始说话后 2s 内出现第一条识别结果（或提示）。
- 完整识别：停止后 10s 内得到最终文本。
- 弱网场景：不出现无解释的 `Load failed`；必须给出“当前不可用原因+可操作建议”。

### 7.2 LLM 语义解析（文本→结构化）
- 20 字以内：5s 内返回结果；100 字以内：10s 内返回结果。
- 返回 JSON 可解析且字段完整率达到 95%（项目/分类/金额/日期）。

